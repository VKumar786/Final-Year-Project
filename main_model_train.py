# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QtdtK8G4FDX8JUzMtRmH-yqoaPvbH-5m

> Importing Dependencies
"""

import pickle
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

"""> Data Collection and Analysis

> PIMA Diabetes Dataset
"""

# Loading diabetes Dataset
diabetes_dataset = pd.read_csv('/content/diabetes.csv')

# Printing first 5 rows of dataset
diabetes_dataset.head()

# number of rows & column in dataset
diabetes_dataset.shape

# getting statistical measures of data
diabetes_dataset.describe()

diabetes_dataset["Outcome"].value_counts()

"""> 1 -> Diabetic & vice - versa"""

diabetes_dataset.groupby("Outcome").mean()

# Seprating data and labels
# axis = 1 -> column, 0 -> row
x = diabetes_dataset.drop(columns="Outcome", axis=1)
y = diabetes_dataset["Outcome"]

print(x)

print(y)

"""> Data Standardization"""

scaler = StandardScaler()

scaler.fit(x)

standardized_data = scaler.transform(x)

print(standardized_data)

x = standardized_data

"""> Train Test Split"""

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, stratify=y, random_state=2)

print(x.shape, x_train.shape, x_test.shape)

"""> Training model"""

classifier = svm.SVC(kernel='linear')

# training support vector machine
classifier.fit(x_train, y_train)

"""> Model Evaluation | Accuracy Score"""

x_train_prediction = classifier.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction, y_train)

# Accuracy score of training data
print(training_data_accuracy)

x_test_prediction = classifier.predict(x_test)
testing_data_accuracy = accuracy_score(x_test_prediction, y_test)

# Accuracy score of testing data
print(testing_data_accuracy)

input_data = (0, 137, 40, 35, 168, 43.1, 2.288, 33)

# change input to numpy array
id_np_arr = np.asarray(input_data)

# reshape array as we are predicting for one instance
id_reshaped = id_np_arr.reshape(1, -1)

# Standardized as we have done to model
id_std = scaler.transform(id_reshaped)

print(id_std)

predict = classifier.predict(id_std)

if predict[0] == 0:
    print("Person is not diabetic")
else:
    print("Person is diabetic")

"""> Saving trained model"""


pickle.dump(classifier, open('trained_model.sav', 'wb'))

# loading saved model
load_model = pickle.load(open('trained_model.sav', 'rb'))

input_data = (0, 137, 40, 35, 168, 43.1, 2.288, 33)

# change input to numpy array
id_np_arr = np.asarray(input_data)

# reshape array as we are predicting for one instance
id_reshaped = id_np_arr.reshape(1, -1)

# Standardized as we have done to model
id_std = scaler.transform(id_reshaped)

predict = load_model.predict(id_std)

if predict[0] == 0:
    print("Person is not diabetic")
else:
    print("Person is diabetic")
